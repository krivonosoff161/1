#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ size –¥–ª—è SHORT –ø–æ–∑–∏—Ü–∏–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ bundle
"""

import csv
import json
import hashlib
from pathlib import Path
from datetime import datetime

def calculate_md5(file_path):
    """–í—ã—á–∏—Å–ª—è–µ—Ç MD5 —Ö–µ—à —Ñ–∞–π–ª–∞"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def check_trades_signs(trades_file):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–Ω–∞–∫–∏ size –¥–ª—è SHORT –ø–æ–∑–∏—Ü–∏–π"""
    print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–∫–æ–≤ size –≤ {trades_file}...")
    
    issues = []
    with open(trades_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader, start=1):
            if row['side'].lower() == 'short':
                size = float(row['size'].replace('"', ''))
                if size > 0:
                    issues.append((i, row['symbol'], size))
    
    if issues:
        print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(issues)} –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
        return False
    else:
        print("‚úÖ –í—Å–µ SHORT –ø–æ–∑–∏—Ü–∏–∏ –∏–º–µ—é—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π size")
        return True

def update_bundle():
    """–û–±–Ω–æ–≤–∏—Ç—å bundle, —É–±—Ä–∞–≤ –æ—à–∏–±–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏"""
    bundle_file = "audit_bundle_20251207_futures_scalping.json"
    
    with open(bundle_file, 'r', encoding='utf-8') as f:
        bundle = json.load(f)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º trades —Å –Ω–æ–≤—ã–º MD5 –∏ —É–±–∏—Ä–∞–µ–º integrity_errors
    trades_file = Path("logs/futures/archived/logs_2025-12-07_16-03-39_extracted/trades_2025-12-07.csv")
    if trades_file.exists():
        stat = trades_file.stat()
        bundle["files"]["trades"]["md5_hash"] = calculate_md5(trades_file)
        bundle["files"]["trades"]["date_modified"] = datetime.fromtimestamp(stat.st_mtime).isoformat()
        bundle["files"]["trades"]["file_size_bytes"] = stat.st_size
        
        # –û–±–Ω–æ–≤–ª—è–µ–º integrity_errors - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
        if "integrity_errors" in bundle["files"]["trades"]:
            bundle["files"]["trades"]["integrity_errors"] = {
                "qty_signs": {
                    "status": "fixed",
                    "note": "All SHORT positions now have negative size values",
                    "fixed_at": datetime.now().isoformat()
                }
            }
        
        print(f"‚úÖ Bundle –æ–±–Ω–æ–≤–ª–µ–Ω: {bundle_file}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    with open(bundle_file, 'w', encoding='utf-8') as f:
        json.dump(bundle, f, indent=2, ensure_ascii=False)
    
    return bundle

def main():
    print("=" * 70)
    print("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–ù–ê–ö–û–í SIZE –î–õ–Ø SHORT –ü–û–ó–ò–¶–ò–ô")
    print("=" * 70)
    
    trades_file = "logs/futures/archived/logs_2025-12-07_16-03-39_extracted/trades_2025-12-07.csv"
    
    if Path(trades_file).exists():
        is_ok = check_trades_signs(trades_file)
        print("\nüì¶ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ bundle...")
        update_bundle()
        if is_ok:
            print("\n‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã, bundle –æ–±–Ω–æ–≤–ª–µ–Ω!")
        else:
            print("\n‚ö†Ô∏è Bundle –æ–±–Ω–æ–≤–ª–µ–Ω, –Ω–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏")
    else:
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {trades_file}")

if __name__ == "__main__":
    main()

