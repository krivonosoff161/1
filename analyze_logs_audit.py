#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""–ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤ –ø–æ AUDIT_CHECKLIST.md"""

import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple


class AuditLogAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–æ–≥–æ–≤ –ø–æ —á–µ–∫-–ª–∏—Å—Ç—É –∞—É–¥–∏—Ç–∞"""

    def __init__(self, logs_dir: Path):
        self.logs_dir = logs_dir
        self.results = {
            "hardcoded_numbers": [],
            "hardcoded_symbols": [],
            "missing_logs": defaultdict(list),
            "missing_warnings": [],
            "race_conditions": [],
            "resource_leaks": [],
            "missing_filters": [],
            "adaptive_reload": [],
            "drift_issues": [],
            "cast_errors": [],
            "graceful_shutdown": [],
            "exponential_backoff": [],
        }

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ª–æ–≥–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        self.required_logs = {
            "SIGNAL_SKIP": r"SIGNAL_SKIP|signal.*skip|–ø—Ä–æ–ø—É—Å–∫.*—Å–∏–≥–Ω–∞–ª",
            "EXIT_HIT": r"EXIT_HIT|exit.*hit|–∑–∞–∫—Ä—ã—Ç–∏–µ.*–ø–æ–∑–∏—Ü–∏",
            "DRIFT_ADD": r"DRIFT_ADD|drift.*add|–¥–æ–±–∞–≤–ª–µ–Ω.*drift",
            "DRIFT_REMOVE": r"DRIFT_REMOVE|drift.*remove|—É–¥–∞–ª–µ–Ω.*drift",
            "TRAIL_UPDATE": r"TRAIL_UPDATE|trail.*update|–æ–±–Ω–æ–≤–ª–µ–Ω.*trail",
            "TRAIL_RELOAD": r"TRAIL_RELOAD|trail.*reload|–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω.*trail",
            "FILL_LATENCY": r"FILL.*latency|latency.*fill|–∑–∞–¥–µ—Ä–∂–∫–∞.*–∏—Å–ø–æ–ª–Ω–µ–Ω–∏",
        }

        # WARNING –ø–æ—Ä–æ–≥–∏
        self.warning_thresholds = {
            "slippage": (r"slippage[:\s]+([\d.]+)", 0.2, "slippage > 0.2%"),
            "exit_slippage": (
                r"exit.*slippage[:\s]+([\d.]+)",
                0.3,
                "exit_slippage > 0.3%",
            ),
            "trail_distance": (
                r"trail.*distance[:\s]+([\d.]+)",
                0.05,
                "trail_distance < 0.05%",
            ),
            "latency": (r"latency[:\s]+(\d+)", 300, "latency > 300 –º—Å"),
        }

    def find_all_logs(self) -> List[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ log —Ñ–∞–π–ª—ã"""
        log_files = []

        # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
        for log_file in self.logs_dir.rglob("*.log"):
            if log_file.is_file():
                log_files.append(log_file)

        return sorted(log_files, key=lambda x: x.stat().st_mtime, reverse=True)

    def analyze_file(self, log_file: Path):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ª–æ–≥–æ–≤"""
        try:
            with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
                lines = content.split("\n")

                for line_num, line in enumerate(lines, 1):
                    self.check_hardcoded_numbers(line, log_file, line_num)
                    self.check_hardcoded_symbols(line, log_file, line_num)
                    self.check_required_logs(line, log_file, line_num)
                    self.check_warning_thresholds(line, log_file, line_num)
                    self.check_race_conditions(line, log_file, line_num)
                    self.check_resource_leaks(line, log_file, line_num)
                    self.check_missing_filters(line, log_file, line_num)
                    self.check_adaptive_reload(line, log_file, line_num)
                    self.check_drift_issues(line, log_file, line_num)
                    self.check_cast_errors(line, log_file, line_num)
                    self.check_graceful_shutdown(line, log_file, line_num)
                    self.check_exponential_backoff(line, log_file, line_num)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {log_file}: {e}")

    def check_hardcoded_numbers(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–¥-–∫–æ–¥–∞ —á–∏—Å–µ–ª"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã: = 0.05, = 5, > 25, == "trending"
        patterns = [
            (r"=\s*0\.0[1-9]\d*", "–ú–∞–≥–∏—á–µ—Å–∫–æ–µ —á–∏—Å–ª–æ 0.0X"),
            (r"=\s*[1-9]\d*\s*[,\n]", "–ú–∞–≥–∏—á–µ—Å–∫–æ–µ —á–∏—Å–ª–æ"),
            (r">\s*2[5-9]|>\s*[3-9]\d+", "–•–∞—Ä–¥-–∫–æ–¥ –ø–æ—Ä–æ–≥–∞ > 25"),
        ]

        for pattern, desc in patterns:
            if re.search(pattern, line):
                # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –∫–æ–Ω—Ñ–∏–≥–∏
                if not any(x in line.lower() for x in ["#", "config", "yaml", "json"]):
                    self.results["hardcoded_numbers"].append(
                        {
                            "file": str(file),
                            "line": line_num,
                            "content": line.strip()[:100],
                            "issue": desc,
                        }
                    )

    def check_hardcoded_symbols(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–¥-–∫–æ–¥–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
        pattern = r'if\s+symbol\s*==\s*["\']([A-Z]+)["\']'
        matches = re.findall(pattern, line)

        for symbol in matches:
            self.results["hardcoded_symbols"].append(
                {
                    "file": str(file),
                    "line": line_num,
                    "symbol": symbol,
                    "content": line.strip()[:100],
                }
            )

    def check_required_logs(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤"""
        for log_type, pattern in self.required_logs.items():
            if re.search(pattern, line, re.IGNORECASE):
                self.results["missing_logs"][log_type].append(
                    {"file": str(file), "line": line_num, "found": True}
                )

    def check_warning_thresholds(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ WARNING –ø–æ—Ä–æ–≥–æ–≤"""
        for threshold_name, (pattern, max_val, desc) in self.warning_thresholds.items():
            match = re.search(pattern, line, re.IGNORECASE)
            if match:
                try:
                    value = float(match.group(1))
                    if threshold_name == "latency":
                        if value > max_val:
                            self.results["missing_warnings"].append(
                                {
                                    "file": str(file),
                                    "line": line_num,
                                    "threshold": desc,
                                    "value": value,
                                    "content": line.strip()[:100],
                                }
                            )
                    else:  # slippage, exit_slippage, trail_distance
                        if threshold_name == "trail_distance":
                            if value < max_val:
                                self.results["missing_warnings"].append(
                                    {
                                        "file": str(file),
                                        "line": line_num,
                                        "threshold": desc,
                                        "value": value,
                                        "content": line.strip()[:100],
                                    }
                                )
                        else:
                            if value > max_val:
                                self.results["missing_warnings"].append(
                                    {
                                        "file": str(file),
                                        "line": line_num,
                                        "threshold": desc,
                                        "value": value,
                                        "content": line.strip()[:100],
                                    }
                                )
                except:
                    pass

    def check_race_conditions(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ race conditions"""
        patterns = [
            (r"KeyError", "KeyError –ø—Ä–∏ –¥–æ—Å—Ç—É–ø–µ –∫ –ø–æ–∑–∏—Ü–∏—è–º", False),
            (r"double.*fill|–¥–≤–æ–π–Ω–æ–µ.*–∏—Å–ø–æ–ª–Ω–µ–Ω", "Double fill", False),
            (r"duplicate.*posId|–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω.*posId", "Double posId", False),
            (r"asyncio\.Lock", "asyncio.Lock –Ω–∞–π–¥–µ–Ω", True),  # –≠—Ç–æ —Ö–æ—Ä–æ—à–æ
        ]

        for pattern, desc, is_good in patterns:
            if re.search(pattern, line, re.IGNORECASE):
                if is_good:
                    # –≠—Ç–æ —Ö–æ—Ä–æ—à–æ - Lock –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    continue
                self.results["race_conditions"].append(
                    {
                        "file": str(file),
                        "line": line_num,
                        "issue": desc,
                        "content": line.strip()[:100],
                    }
                )

    def check_resource_leaks(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–µ—á–µ–∫ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        patterns = [
            (r"create_task.*without.*cancel", "Task leak"),
            (r"websocket.*reconnect.*leak", "TCP-handles leak"),
            (r"RSS.*>.*5%", "RSS > +5%"),
            (r"unclosed.*connection", "–ù–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"),
        ]

        for pattern, desc in patterns:
            if re.search(pattern, line, re.IGNORECASE):
                self.results["resource_leaks"].append(
                    {
                        "file": str(file),
                        "line": line_num,
                        "issue": desc,
                        "content": line.strip()[:100],
                    }
                )

    def check_missing_filters(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
        # –ò—â–µ–º –º–µ—Å—Ç–∞, –≥–¥–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è signal –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        if "return signal" in line.lower() or "return.*signal" in line.lower():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∏–ª—å—Ç—Ä—ã –≤—ã—à–µ
            pass  # –≠—Ç–æ —Å–ª–æ–∂–Ω–µ–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

    def check_adaptive_reload(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ adaptive-–ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ regime"""
        if "regime.*change" in line.lower() or "—Å–º–µ–Ω–∞.*—Ä–µ–∂–∏–º" in line.lower():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if not any(x in line.lower() for x in ["trail", "tp", "sl", "multiplier"]):
                self.results["adaptive_reload"].append(
                    {
                        "file": str(file),
                        "line": line_num,
                        "issue": "–°–º–µ–Ω–∞ regime –±–µ–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
                        "content": line.strip()[:100],
                    }
                )

    def check_drift_issues(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ drift —Ä–µ–µ—Å—Ç—Ä–∞"""
        if "drift" in line.lower():
            if "sync_positions" in line.lower():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–æ—Ç—É —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                if "60" not in line and "sync.*60" not in line.lower():
                    self.results["drift_issues"].append(
                        {
                            "file": str(file),
                            "line": line_num,
                            "issue": "sync_positions –Ω–µ –∫–∞–∂–¥—ã–µ 60 —Å–µ–∫",
                            "content": line.strip()[:100],
                        }
                    )

    def check_cast_errors(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö cast-–æ–≤"""
        patterns = [
            (r"TypeError.*str.*int", "str > int (TypeError)"),
            (r'ValueError.*float.*["\']', 'float("") (ValueError)'),
            (
                r'position\.get\(["\']size["\']\)\s*[^float]',
                'position.get("size") –±–µ–∑ float()',
            ),
        ]

        for pattern, desc in patterns:
            if re.search(pattern, line, re.IGNORECASE):
                self.results["cast_errors"].append(
                    {
                        "file": str(file),
                        "line": line_num,
                        "issue": desc,
                        "content": line.strip()[:100],
                    }
                )

    def check_graceful_shutdown(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ graceful-shutdown"""
        if "rss" in line.lower() or "memory" in line.lower():
            if "600" in line or "shutdown" in line.lower():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ graceful shutdown
                if "graceful" not in line.lower() and "shutdown" in line.lower():
                    self.results["graceful_shutdown"].append(
                        {
                            "file": str(file),
                            "line": line_num,
                            "issue": "Shutdown –±–µ–∑ graceful",
                            "content": line.strip()[:100],
                        }
                    )

    def check_exponential_backoff(self, line: str, file: Path, line_num: int):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ exponential backoff"""
        if "reconnect" in line.lower():
            if "exponential" not in line.lower() and "backoff" not in line.lower():
                if "delay" in line.lower() or "attempt" in line.lower():
                    self.results["exponential_backoff"].append(
                        {
                            "file": str(file),
                            "line": line_num,
                            "issue": "Reconnect –±–µ–∑ exponential backoff",
                            "content": line.strip()[:100],
                        }
                    )

    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç"""
        report = []
        report.append("=" * 80)
        report.append("üìã –ê–£–î–ò–¢ –õ–û–ì–û–í –ü–û CHECKLIST")
        report.append("=" * 80)
        report.append("")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∞–∑–¥–µ–ª—É
        sections = [
            (1, "–•–∞—Ä–¥-–∫–æ–¥ —á–∏—Å–µ–ª", "hardcoded_numbers"),
            (2, "–•–∞—Ä–¥-–∫–æ–¥ —Å–∏–º–≤–æ–ª–æ–≤", "hardcoded_symbols"),
            (3, "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ª–æ–≥–æ–≤", "missing_logs"),
            (4, "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ WARNING-–ø–æ—Ä–æ–≥–æ–≤", "missing_warnings"),
            (5, "Race-conditions", "race_conditions"),
            (6, "–£—Ç–µ—á–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤", "resource_leaks"),
            (7, "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤", "missing_filters"),
            (8, "–ù–µ—Ç adaptive-–ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏", "adaptive_reload"),
            (9, "Drift —Ä–µ–µ—Å—Ç—Ä–∞ ‚Üî –±–∏—Ä–∂–∞", "drift_issues"),
            (10, "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ cast-—ã", "cast_errors"),
            (11, "–ù–µ—Ç graceful-shutdown", "graceful_shutdown"),
            (12, "–ù–µ—Ç exponential backoff", "exponential_backoff"),
        ]

        total_red = 0
        total_warning = 0

        for num, name, key in sections:
            issues = self.results[key]

            if key == "missing_logs":
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –ª–æ–≥–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç
                found_logs = set(issues.keys())
                required_logs = set(self.required_logs.keys())
                missing = required_logs - found_logs

                if missing:
                    status = "üî¥"
                    total_red += 1
                    comment = f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ª–æ–≥–∏: {', '.join(missing)}"
                else:
                    status = "‚úÖ"
                    comment = "–í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ª–æ–≥–∏ –Ω–∞–π–¥–µ–Ω—ã"
            else:
                if issues:
                    if num in [1, 2, 4, 5, 6, 10]:  # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ
                        status = "üî¥"
                        total_red += len(issues)
                    else:
                        status = "‚ö†Ô∏è"
                        total_warning += len(issues)
                    comment = f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(issues)}"
                else:
                    status = "‚úÖ"
                    comment = "–ü—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

            report.append(f"### {num}. {name}")
            report.append(f"–°—Ç–∞—Ç—É—Å: {status}")
            report.append(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment}")

            if issues and key != "missing_logs":
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤
                for issue in list(issues)[:5]:
                    file_name = Path(issue["file"]).name
                    report.append(
                        f"  - {file_name}:{issue.get('line', '?')} - {issue.get('issue', issue.get('threshold', ''))}"
                    )
                if len(issues) > 5:
                    report.append(f"  ... –∏ –µ—â–µ {len(issues) - 5} –ø—Ä–æ–±–ª–µ–º")

            report.append("")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
        report.append("=" * 80)
        report.append("üìä –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê")
        report.append("=" * 80)
        report.append("")
        report.append(f"üî¥ –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º: {total_red}")
        report.append(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {total_warning}")
        report.append("")

        if total_red == 0 and total_warning == 0:
            report.append("‚úÖ GO-LIVE: –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã!")
        elif total_red == 0:
            report.append("‚ö†Ô∏è GO-LIVE: –ï—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –Ω–æ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç")
        else:
            report.append("üî¥ GO-LIVE: –ë–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è –∫—Ä–∏—Ç–∏—á–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏")

        return "\n".join(report)

    def analyze(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        print("üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤...")

        log_files = self.find_all_logs()
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ log —Ñ–∞–π–ª–æ–≤: {len(log_files)}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Ñ–∞–π–ª–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã
        for log_file in log_files[:10]:
            print(f"  –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é: {log_file.name}")
            self.analyze_file(log_file)

        return self.generate_report()


def main():
    logs_dir = Path("logs/futures/archived")

    if not logs_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {logs_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return

    analyzer = AuditLogAnalyzer(logs_dir)
    report = analyzer.analyze()

    print("\n" + report)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_file = Path("AUDIT_REPORT.md")
    report_file.write_text(report, encoding="utf-8")
    print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")


if __name__ == "__main__":
    main()
