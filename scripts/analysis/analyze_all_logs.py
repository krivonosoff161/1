#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ª–æ–≥–æ–≤ –∏ –∫–æ–¥–∞"""

import os
import re
import zipfile
from collections import defaultdict
from pathlib import Path


def analyze_all_logs():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –ª–æ–≥–∏ –≤–∫–ª—é—á–∞—è –∞—Ä—Ö–∏–≤—ã"""

    print("=" * 80)
    print("–ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –í–°–ï–• –õ–û–ì–û–í –ò –ö–û–î–ê")
    print("=" * 80)

    # –ü—É—Ç–∏
    futures_logs_dir = Path("logs/futures")
    current_log = futures_logs_dir / "futures_main_2025-11-24.log"

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫
    errors = defaultdict(list)
    critical_closes = []
    zero_duration_issues = []

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π –ª–æ–≥
    if current_log.exists():
        print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –ª–æ–≥–∞: {current_log.name}")
        analyze_log_file(current_log, errors, critical_closes, zero_duration_issues)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—Ä—Ö–∏–≤—ã
    zip_files = list(futures_logs_dir.glob("*.zip"))
    print(f"\nüì¶ –ù–∞–π–¥–µ–Ω–æ –∞—Ä—Ö–∏–≤–æ–≤: {len(zip_files)}")

    analyzed_count = 0
    for zip_file in sorted(zip_files, key=lambda x: x.stat().st_mtime, reverse=True)[
        :20
    ]:
        try:
            with zipfile.ZipFile(zip_file, "r") as z:
                for log_name in z.namelist():
                    if log_name.endswith(".log"):
                        with z.open(log_name) as f:
                            # –ß–∏—Ç–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –∫—É—Å–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                            content = f.read(10000).decode("utf-8", errors="ignore")
                            analyze_log_content(
                                content, errors, critical_closes, zero_duration_issues
                            )
                            analyzed_count += 1
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {zip_file.name}: {e}")

    print(f"\n‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ª–æ–≥–æ–≤: {analyzed_count}")

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 80)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 80)

    if errors:
        print(f"\n‚ùå –ù–∞–π–¥–µ–Ω–æ —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫: {len(errors)}")
        for error_type, occurrences in sorted(
            errors.items(), key=lambda x: len(x[1]), reverse=True
        )[:10]:
            print(f"  {error_type}: {len(occurrences)}")

    return errors, critical_closes, zero_duration_issues


def analyze_log_file(log_path, errors, critical_closes, zero_duration_issues):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω –ª–æ–≥ —Ñ–∞–π–ª"""
    try:
        with open(log_path, "r", encoding="utf-8", errors="ignore") as f:
            # –ß–∏—Ç–∞–µ–º –ø–æ —á–∞—Å—Ç—è–º
            chunk_size = 10000
            while True:
                chunk = f.read(chunk_size)
                if not chunk:
                    break
                analyze_log_content(
                    chunk, errors, critical_closes, zero_duration_issues
                )
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {log_path}: {e}")


def analyze_log_content(content, errors, critical_closes, zero_duration_issues):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ª–æ–≥–∞"""
    # –ò—â–µ–º –æ—à–∏–±–∫–∏
    error_patterns = [
        (r"ERROR|CRITICAL", "ERROR/CRITICAL"),
        (r"Exception", "Exception"),
        (r"Traceback", "Traceback"),
        (r"‚ùå", "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞"),
    ]

    for pattern, error_type in error_patterns:
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            errors[error_type].extend(matches)

    # –ò—â–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–∫—Ä—ã—Ç–∏—è
    if "critical_loss_cut_2x" in content:
        critical_closes.append("found")

    # –ò—â–µ–º –ø—Ä–æ–±–ª–µ–º—ã —Å duration
    if "duration_sec.*0\.0|duration.*0" in content:
        zero_duration_issues.append("found")


if __name__ == "__main__":
    errors, critical_closes, zero_duration_issues = analyze_all_logs()
