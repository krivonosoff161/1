"""
–ê—É–¥–∏—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –±–æ—Ç–∞
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∫–ª—é—á–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫—Ä—ã—Ç–∏—è/–∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–π
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ exit mechanisms
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –∏ –æ—à–∏–±–æ–∫
"""

import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set

from loguru import logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()
logger.add(
    lambda msg: print(msg, end=""),
    format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
    level="INFO",
)


class LoggingCoverageAuditor:
    """–ê—É–¥–∏—Ç–æ—Ä –ø–æ–∫—Ä—ã—Ç–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

    def __init__(self):
        self.futures_dir = Path("src/strategies/scalping/futures")
        self.key_operations = {
            "signal_generation": ["generate", "signal", "rsi", "macd", "ma", "bb"],
            "filtering": ["filter", "adx", "mtf", "correlation", "pivot"],
            "position_opening": ["open_position", "entry", "place_order"],
            "position_closing": ["close_position", "exit", "tp", "sl", "trailing"],
            "risk_management": ["risk", "margin", "size", "limit"],
            "order_execution": ["execute", "order", "market", "limit", "fill"],
            "exit_mechanisms": [
                "tp",
                "sl",
                "partial",
                "harvest",
                "timeout",
                "emergency",
            ],
            "regime_detection": ["regime", "trending", "ranging", "choppy"],
            "pnl_calculation": ["pnl", "profit", "loss", "margin"],
            "slippage": ["slippage", "spread", "fill"],
        }

    def find_key_functions(self) -> Dict[str, List[str]]:
        """–ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ –∫–æ–¥–µ"""
        logger.info("üîç –ü–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π...\n")

        functions = defaultdict(list)

        # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        for py_file in self.futures_dir.rglob("*.py"):
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    content = f.read()

                # –ò—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π
                func_pattern = r"async def (\w+)|def (\w+)"
                matches = re.findall(func_pattern, content)

                for match in matches:
                    func_name = match[0] or match[1]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –∫ –∫–ª—é—á–µ–≤—ã–º –æ–ø–µ—Ä–∞—Ü–∏—è–º
                    for op_type, keywords in self.key_operations.items():
                        if any(keyword in func_name.lower() for keyword in keywords):
                            functions[op_type].append(f"{py_file.name}:{func_name}")

            except Exception as e:
                logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {py_file}: {e}")

        return dict(functions)

    def check_logging_in_functions(self) -> Dict[str, Dict[str, bool]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏—è—Ö"""
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏—è—Ö...\n")

        coverage = defaultdict(lambda: defaultdict(bool))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã
        key_files = {
            "signal_generation": [
                "signal_generator.py",
                "coordinators/signal_coordinator.py",
            ],
            "filtering": ["signals/filter_manager.py"],
            "position_opening": ["positions/entry_manager.py"],
            "position_closing": [
                "position_manager.py",
                "positions/exit_analyzer.py",
            ],
            "risk_management": ["risk_manager.py"],
            "order_execution": ["order_executor.py"],
            "exit_mechanisms": [
                "position_manager.py",
                "positions/exit_analyzer.py",
                "indicators/trailing_stop_loss.py",
            ],
            "regime_detection": [
                "adaptivity/regime_manager.py",
                "modules/adaptive_regime_manager.py",
            ],
            "pnl_calculation": [
                "calculations/pnl_calculator.py",
                "position_manager.py",
            ],
            "slippage": ["modules/slippage_guard.py", "order_executor.py"],
        }

        for op_type, files in key_files.items():
            for file_rel in files:
                file_path = self.futures_dir / file_rel
                if file_path.exists():
                    try:
                        with open(file_path, "r", encoding="utf-8") as f:
                            content = f.read()

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                        has_info = "logger.info" in content
                        has_warning = "logger.warning" in content
                        has_error = "logger.error" in content
                        has_debug = "logger.debug" in content

                        coverage[op_type][file_rel] = (
                            has_info or has_warning or has_error or has_debug
                        )

                    except Exception as e:
                        logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")

        return dict(coverage)

    def check_specific_logging(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è...\n")

        checks = {
            "signal_types": False,
            "filters_passed": False,
            "regime_logging": False,
            "slippage_logging": False,
            "partial_tp_logging": False,
            "exit_reasons": False,
            "daily_pnl": False,
            "max_daily_loss": False,
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º signal_coordinator –¥–ª—è —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
        signal_coord_file = self.futures_dir / "coordinators" / "signal_coordinator.py"
        if signal_coord_file.exists():
            with open(signal_coord_file, "r", encoding="utf-8") as f:
                content = f.read()
                checks["signal_types"] = (
                    "signal_type" in content and "logger.info" in content
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º filter_manager –¥–ª—è filters_passed
        filter_mgr_file = self.futures_dir / "signals" / "filter_manager.py"
        if filter_mgr_file.exists():
            with open(filter_mgr_file, "r", encoding="utf-8") as f:
                content = f.read()
                checks["filters_passed"] = (
                    "filters_passed" in content and "logger" in content
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º regime –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        regime_files = [
            self.futures_dir / "adaptivity" / "regime_manager.py",
            self.futures_dir / "modules" / "adaptive_regime_manager.py",
        ]
        for file_path in regime_files:
            if file_path.exists():
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    if "regime" in content.lower() and "logger" in content:
                        checks["regime_logging"] = True
                        break

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º slippage –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        slippage_file = Path("src/strategies/modules/slippage_guard.py")
        order_exec_file = self.futures_dir / "order_executor.py"
        for file_path in [slippage_file, order_exec_file]:
            if file_path.exists():
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    if "slippage" in content.lower() and "logger" in content:
                        checks["slippage_logging"] = True
                        break

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º partial_tp –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        position_mgr_file = self.futures_dir / "position_manager.py"
        if position_mgr_file.exists():
            with open(position_mgr_file, "r", encoding="utf-8") as f:
                content = f.read()
                checks["partial_tp_logging"] = (
                    "partial_tp" in content.lower() and "logger" in content
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º exit_reasons
        exit_analyzer_file = self.futures_dir / "positions" / "exit_analyzer.py"
        if exit_analyzer_file.exists():
            with open(exit_analyzer_file, "r", encoding="utf-8") as f:
                content = f.read()
                checks["exit_reasons"] = (
                    "reason" in content.lower() and "logger" in content
                )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º daily_pnl –∏ max_daily_loss
        risk_mgr_file = self.futures_dir / "risk_manager.py"
        if risk_mgr_file.exists():
            with open(risk_mgr_file, "r", encoding="utf-8") as f:
                content = f.read()
                checks["daily_pnl"] = "daily_pnl" in content and "logger" in content
                checks["max_daily_loss"] = (
                    "max_daily_loss" in content and "logger" in content
                )

        return checks

    def generate_report(self, stats: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        report = []
        report.append("# üîç –ê–£–î–ò–¢ –ü–û–ö–†–´–¢–ò–Ø –õ–û–ì–ò–†–û–í–ê–ù–ò–ï–ú\n")
        report.append("**–î–∞—Ç–∞:** 04.12.2025\n")
        report.append("---\n\n")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        report.append("## ‚úÖ –ü–†–û–í–ï–†–ö–ê –ö–û–ù–ö–†–ï–¢–ù–´–• –¢–ò–ü–û–í –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø\n\n")
        specific = stats.get("specific_logging", {})
        for check_name, has_logging in specific.items():
            status = "‚úÖ" if has_logging else "‚ùå"
            report.append(
                f"{status} **{check_name}**: {'–ï—Å—Ç—å' if has_logging else '–ù–ï–¢'}\n"
            )

        # –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π
        report.append("\n## üìä –ü–û–ö–†–´–¢–ò–ï –ü–û –¢–ò–ü–ê–ú –û–ü–ï–†–ê–¶–ò–ô\n\n")
        coverage = stats.get("function_coverage", {})
        for op_type, files in coverage.items():
            report.append(f"### {op_type.replace('_', ' ').title()}\n\n")
            total = len(files)
            covered = sum(1 for has_logging in files.values() if has_logging)
            report.append(
                f"**–ü–æ–∫—Ä—ã—Ç–∏–µ:** {covered}/{total} ({covered/total*100:.0f}%)\n\n"
            )
            for file_rel, has_logging in files.items():
                status = "‚úÖ" if has_logging else "‚ùå"
                report.append(f"{status} `{file_rel}`\n")

        # –ü—Ä–æ–±–ª–µ–º—ã
        report.append("\n## ‚ö†Ô∏è –ù–ê–ô–î–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´\n\n")
        problems = []
        for check_name, has_logging in specific.items():
            if not has_logging:
                problems.append(f"1. **{check_name}** - –Ω–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")

        if problems:
            for problem in problems:
                report.append(f"- {problem}\n")
        else:
            report.append("‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("\n## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\n\n")
        recommendations = []
        for check_name, has_logging in specific.items():
            if not has_logging:
                recommendations.append(
                    f"1. **–î–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ {check_name}** - –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è"
                )

        if recommendations:
            for rec in recommendations:
                report.append(f"- {rec}\n")
        else:
            report.append("‚úÖ –í—Å–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\n")

        return "".join(report)

    async def run_audit(self):
        """–ó–∞–ø—É—Å–∫ –∞—É–¥–∏—Ç–∞"""
        logger.info("üöÄ –ù–ê–ß–ê–õ–û –ê–£–î–ò–¢–ê –ü–û–ö–†–´–¢–ò–Ø –õ–û–ì–ò–†–û–í–ê–ù–ò–ï–ú\n")
        logger.info("=" * 60 + "\n\n")

        # –ü–æ–∏—Å–∫ —Ñ—É–Ω–∫—Ü–∏–π
        functions = self.find_key_functions()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        function_coverage = self.check_logging_in_functions()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤
        specific_logging = self.check_specific_logging()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            "functions": functions,
            "function_coverage": function_coverage,
            "specific_logging": specific_logging,
        }

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = self.generate_report(stats)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_file = Path("LOGGING_COVERAGE_AUDIT_REPORT.md")
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

        logger.info("\n" + "=" * 60 + "\n")
        logger.info("‚úÖ –ê–£–î–ò–¢ –ó–ê–í–ï–†–®–ï–ù\n")
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}\n")

        # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        logger.info("\nüìä –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
        total_checks = len(specific_logging)
        passed_checks = sum(1 for v in specific_logging.values() if v)
        logger.info(
            f"  –ü—Ä–æ–≤–µ—Ä–æ–∫ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {passed_checks}/{total_checks} ({passed_checks/total_checks*100:.0f}%)\n"
        )


async def main():
    auditor = LoggingCoverageAuditor()
    await auditor.run_audit()


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
