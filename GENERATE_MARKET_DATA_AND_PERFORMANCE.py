#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Ä–∫–µ—Ç-–¥–∞–Ω–Ω—ã—Ö (OHLCV) –∏ Performance Report –¥–ª—è –∞—É–¥–∏—Ç–∞
"""

import asyncio
import csv
import json
from datetime import datetime, timezone
from pathlib import Path
import pandas as pd
import numpy as np
import aiohttp
import yaml

# –°–∏–º–≤–æ–ª—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
SYMBOLS = ["BTC-USDT", "ETH-USDT", "SOL-USDT", "DOGE-USDT", "XRP-USDT"]
DATE = "2025-12-07"
START_TIME = "2025-12-07T14:00:00Z"
END_TIME = "2025-12-07T15:30:00Z"

async def fetch_candles_okx(symbol: str, timeframe: str = "1m", limit: int = 200):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–µ—á–∏ —Å OKX API"""
    inst_id = f"{symbol}-SWAP"
    url = "https://www.okx.com/api/v5/market/candles"
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤ timestamp (–º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã)
    start_dt = datetime.fromisoformat(START_TIME.replace('Z', '+00:00'))
    end_dt = datetime.fromisoformat(END_TIME.replace('Z', '+00:00'))
    start_ts = int(start_dt.timestamp() * 1000)
    end_ts = int(end_dt.timestamp() * 1000)
    
    # –ü—Ä–æ–±—É–µ–º –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π - –ø—Ä–æ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–≤–µ—á–∏
    params = {
        "instId": inst_id,
        "bar": timeframe,
        "limit": str(limit)
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if data.get("code") == "0" and data.get("data"):
                        candles = []
                        for candle_data in data["data"]:
                            if len(candle_data) >= 6:
                                ts_ms = int(candle_data[0])
                                ts_sec = ts_ms // 1000
                                candles.append({
                                    "timestamp": datetime.fromtimestamp(ts_sec, tz=timezone.utc).isoformat(),
                                    "symbol": symbol,
                                    "open": float(candle_data[1]),
                                    "high": float(candle_data[2]),
                                    "low": float(candle_data[3]),
                                    "close": float(candle_data[4]),
                                    "volume": float(candle_data[5]),
                                    "quote_currency": "USDT"
                                })
                        return candles
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ—á–µ–π –¥–ª—è {symbol}: {e}")
    
    return []

async def generate_market_data():
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å market_data.csv"""
    print("üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞—Ä–∫–µ—Ç-–¥–∞–Ω–Ω—ã—Ö —Å OKX...")
    
    all_candles = []
    for symbol in SYMBOLS:
        print(f"   –ó–∞–ø—Ä–∞—à–∏–≤–∞—é {symbol}...")
        candles = await fetch_candles_okx(symbol, "1m", 200)
        all_candles.extend(candles)
        print(f"   ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(candles)} —Å–≤–µ—á–µ–π –¥–ª—è {symbol}")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp
    all_candles.sort(key=lambda x: x["timestamp"])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    output_file = f"logs/futures/archived/logs_2025-12-07_16-03-39_extracted/market_data_{DATE}.csv"
    Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=["timestamp", "symbol", "open", "high", "low", "close", "volume", "quote_currency"])
        writer.writeheader()
        writer.writerows(all_candles)
    
    print(f"‚úÖ –ú–∞—Ä–∫–µ—Ç-–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file} ({len(all_candles)} —Å–≤–µ—á–µ–π)")
    return output_file, all_candles

def calculate_performance_metrics(trades_df, market_data_df=None):
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    if len(trades_df) == 0:
        return {}
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_trades = len(trades_df)
    winning_trades = len(trades_df[trades_df["net_pnl"] > 0])
    losing_trades = len(trades_df[trades_df["net_pnl"] < 0])
    win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
    
    total_pnl = float(trades_df["net_pnl"].sum())
    total_commission = float(trades_df["commission"].sum())
    gross_pnl = float(trades_df["gross_pnl"].sum())
    
    avg_trade = total_pnl / total_trades if total_trades > 0 else 0
    avg_winning_trade = float(trades_df[trades_df["net_pnl"] > 0]["net_pnl"].mean()) if winning_trades > 0 else 0
    avg_losing_trade = float(trades_df[trades_df["net_pnl"] < 0]["net_pnl"].mean()) if losing_trades > 0 else 0
    
    largest_win = float(trades_df["net_pnl"].max()) if total_trades > 0 else 0
    largest_loss = float(trades_df["net_pnl"].min()) if total_trades > 0 else 0
    
    # Profit Factor
    total_wins = float(trades_df[trades_df["net_pnl"] > 0]["net_pnl"].sum()) if winning_trades > 0 else 0
    total_losses = abs(float(trades_df[trades_df["net_pnl"] < 0]["net_pnl"].sum())) if losing_trades > 0 else 0
    profit_factor = total_wins / total_losses if total_losses > 0 else 0
    
    # Consecutive wins/losses
    consecutive_wins = 0
    consecutive_losses = 0
    max_consecutive_wins = 0
    max_consecutive_losses = 0
    
    for pnl in trades_df["net_pnl"]:
        if pnl > 0:
            consecutive_wins += 1
            consecutive_losses = 0
            max_consecutive_wins = max(max_consecutive_wins, consecutive_wins)
        else:
            consecutive_losses += 1
            consecutive_wins = 0
            max_consecutive_losses = max(max_consecutive_losses, consecutive_losses)
    
    # Avg holding time
    avg_holding_minutes = float(trades_df["duration_sec"].mean() / 60) if "duration_sec" in trades_df.columns else 0
    
    metrics = {
        "sharpe_ratio": None,  # –¢—Ä–µ–±—É–µ—Ç returns
        "sortino_ratio": None,  # –¢—Ä–µ–±—É–µ—Ç returns
        "calmar_ratio": None,  # –¢—Ä–µ–±—É–µ—Ç CAGR –∏ max_dd
        "cagr": None,  # –¢—Ä–µ–±—É–µ—Ç –ø–µ—Ä–∏–æ–¥ –∏ –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª
        "max_drawdown": None,  # –¢—Ä–µ–±—É–µ—Ç equity curve
        "max_drawdown_duration": None,
        "win_rate": round(win_rate, 2),
        "profit_factor": round(profit_factor, 2) if profit_factor > 0 else 0,
        "avg_trade": round(avg_trade, 4),
        "avg_winning_trade": round(avg_winning_trade, 4),
        "avg_losing_trade": round(avg_losing_trade, 4),
        "avg_bars_in_trade": None,  # –¢—Ä–µ–±—É–µ—Ç market data
        "total_trades": total_trades,
        "winning_trades": winning_trades,
        "losing_trades": losing_trades,
        "total_pnl": round(total_pnl, 4),
        "total_commission": round(total_commission, 4),
        "net_pnl": round(total_pnl, 4),
        "max_consecutive_wins": max_consecutive_wins,
        "max_consecutive_losses": max_consecutive_losses,
        "largest_win": round(largest_win, 4),
        "largest_loss": round(largest_loss, 4),
        "avg_holding_time_minutes": round(avg_holding_minutes, 2)
    }
    
    return metrics

def generate_performance_report(trades_file, market_data_file=None):
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å performance_report.yaml"""
    print("\nüìà –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Performance Report...")
    
    # –ß–∏—Ç–∞–µ–º trades
    trades_df = pd.read_csv(trades_file)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = calculate_performance_metrics(trades_df)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = {
        "metrics": metrics,
        "period": {
            "start": DATE,
            "end": DATE,
            "days": 1
        },
        "benchmark": {
            "name": None,
            "return": None,
            "sharpe": None
        },
        "additional": {
            "max_consecutive_wins": metrics.get("max_consecutive_wins", 0),
            "max_consecutive_losses": metrics.get("max_consecutive_losses", 0),
            "largest_win": metrics.get("largest_win", 0),
            "largest_loss": metrics.get("largest_loss", 0),
            "avg_holding_time_minutes": metrics.get("avg_holding_time_minutes", 0)
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = f"logs/futures/archived/logs_2025-12-07_16-03-39_extracted/performance_report_{DATE}.yaml"
    Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(report, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    
    print(f"‚úÖ Performance Report —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    return output_file

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 70)
    print("üìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• –î–õ–Ø –ê–£–î–ò–¢–ê")
    print("=" * 70)
    
    # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–∞—Ä–∫–µ—Ç-–¥–∞–Ω–Ω—ã–µ
    market_data_file, candles = await generate_market_data()
    
    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Performance Report
    trades_file = "logs/futures/archived/logs_2025-12-07_16-03-39_extracted/trades_2025-12-07.csv"
    if Path(trades_file).exists():
        performance_file = generate_performance_report(trades_file, market_data_file)
        print(f"\n‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
        print(f"   üìÑ Market Data: {market_data_file}")
        print(f"   üìÑ Performance Report: {performance_file}")
    else:
        print(f"\n‚ö†Ô∏è –§–∞–π–ª trades –Ω–µ –Ω–∞–π–¥–µ–Ω: {trades_file}")

if __name__ == "__main__":
    asyncio.run(main())

